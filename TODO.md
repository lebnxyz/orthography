# TODO

* finish verb initializer (man)
    * ~~collapse `long vowel.long vowel` sequences (generated by conjugating a final-weak verb) into just the second vowel~~
    * ~~implement nfa3al-i fta3al-i and nfa3al-a fta3al-a forms (or maybe **nfi3il/fti3il & nfa3al/fta3al** even tho that breaks the pattern of using 3ms.pst)~~
    * ~~make sure f3ii and f3aa imperatives are in place~~
    * ~~add all of fa3yit, fi3yit, fi3it, fa3it~~
    * ~~make sure parseWord is upholding the stress in stuff like `` $`+nFi -3iL` ``~~
    * Figure out how to vary between tinsaani\~tinsiini (both for masc), 2it7addaak\~2it7addiik, etc.
* ~~delete stAf3al from verb and pp (probably)~~
* ~~account for final-vowel-plus-suffix combos like mfa33aa+c == mfa33aayc in pp's initializer~~
* ~~add `(2af3al ...)` tag to grammar~~
* ~~add `(taf3il ...)` tag to grammar (takes a root and generates $`t.a/i.${$F} ${$3}.ii.${$L}`) **plus t.a/i.F.3.i.y.c \~ t.a/i.F.3.aa.y.c**~~
* ~~Add `(ctx ...)` tag to grammar, e.g. `(ctx [proper noun] [tense final vowel] jOni)` or `(ctx [self] s*arr~1ms)`, `ma (ctx [stress] (verb [3ms] [u] [pst] q{w}l|2fs))`~~
* implement the other tags smh
* ~~change mu- to mi- in pp~~
* ~~turn pronoun objects' boolean attrs into methods~~
* ~~add postTransform to parseWord and figure out a way to handle combinations...~~
* Make augmenting a distinct step and allow multiple augmentations (no reason why it couldn't happen!)
* ~~Add metadata to consonants: place, manner, voicing **(grouped by articulator instead of place)**~~
* ~~Update style: enforce commas on the last element of multiline lists, enforce curly-internal spaces only for blocks and not objects~~
* ~~Create a module that exports string tags to map certain strings to numbers (basically what's currently in phoneme-properties.js) **(enums)**~~
* ~~a/i is weird and shouldn't exist... BUT it's useful on the backend side of things because it helps me avoid duplicating stuff. As a compromise between
  **obliterating it** and letting it fester and make everything gross, just find a way to make sure that anything containing a/i is always expanded out
  into two separate options (one with a, one with i) before it reaches the transformer stage~~
* ~~Remove meta.t attribute from feminine suffix~~
* deal with emphatic Z from ص vs. emphatic Z from ظ
* add nisbe (with the symbol % lol) to grammar
* remove schwa from alphabet & grammar
  * can't figure out how to replace schwa, maybe one of these options:
    * in Word (before Capture is even a thing), add nulls or noschwas between all consonant pairs in order to make space for future possible schwas (including ones that aren't originally necessary but arise out of vowel-deletion)
    * or: figure out a way to capture the space **between** segments with a Capture.between() method... hmph
  * either figure out how to let noschwa be added between syllables (as in CVC_Ci...) or remove it too
    * if removed, replace it with a specific transform rule that allows schwa not to be inserted between two consonants AB where (1) A's articulator is within distance 1 of B's, and (2) A is more sonorous than B; this covers most cases like إنت، الهند، دست، يستناول, etc... even tho it doesn't allow special-casing كرفس and نفس  (maybe those are iffy anyway)
* figure out some kind of pre-handler stage where suffixes (`%` nisbe, `c` fsg, `C` fpl, `=` dual, `+` plural) and verb-conjugation prefixes are expanded into normal letters... in a way that both lets them be toggled and also lets their individual letters be toggled/behave as normal parts of the word
* probably remove the index-caching stuff from Capture, schwa-insertion and the pre-handler thingy makes it tough to deal with (can always try to work out a similar efficiency solution later)
* NO MORE TRANSFORM FUNCS!!!
  * instead of a method chain like `capture.segment().handle(({envParam}) => { if (envParam === value) return [bruh, bruv]; })`,
    make it `transform.segment().into([bruh, bruv]).where({envParam: value}).because(reason)`
    * this means transforms and deps are no longer black boxes, making them easier to analyze and modify programmatically
    * it also forces transforms to only go one-to-one, making it easy to tie a specific reason to each transform
  * this obviates the whole overengineered (even if kinda cool) param-grabby thingy 😔
  * the `reason` should apply to the transformation and all of its options, not individual options like I was originally thinking  
    (e.g. instead of "some people pronounce alif as O around emphatics" "some people pronounce alif as A around emphatics" just do "emphatics change the pronunciation of nearby alifs. some people round to O etc")
  * possibly do `{bruh: 0.5, bruv: 0.5}` instead of an array to handle probabilistic outputs
* Split `ipa-phonemic` into a few modules: `common` for utils and classes (might have submodules for diff classes), `iconophonemic`, `phonemic`, `phonetic`, and maybe `random`
    * `iconophonemic`: for scripts that will have fixed iconic symbols for ة and stuff, and also adhere to archiphonemes like `aa` and `ay/aw`; can maybe specify which phoneme groups should be abstracted over in that way (eg i want -iin to be -iin instead of a symbol, and if not that then the transformer will maybe do something like `iconophonemicAlphabet.iin.contracted || iconophonemicAlphabet.iin.default, iconophonemicAlphabet.iin.full || iconophonemicAlphabet.iin.default, etc`
    * `phonemic`: for scripts that are based on phonemes and have none of those icons^, so this transformer will translate `abc.c` into `[abc.e, abc.i]` or something and then surface it as whichever one of those two would surface -- instead of leaving it as `abc.c` and surfacing it as `iconophonemicAlphabet.c.lowered/raised || iconophonemicAlphabet.c.default`
    * `phonetic`: this one is gonna be a pain in the neck and i'm probably gonna put it off
    * `random`: not exactly sure how this will work but it's for 3arabizi and stuff where vowels might just disappear no matter what they are... also geminates need to be only randomly observed
* Maybe let alphabets have transformers of their own, eg a meme ->katakana transformer could first do romaji like `abc.t abc.u` -> `"tu"` and then have the `"tu"` be processed into `"ツ"`
* for the fabled U(n)I(corn): when you click on a letter in a word it gives you both the list of options and the probability slider for each option. the sliders affect all instances of that segment in that environment, not just that particular segment; correspondingly, you can click on any one of the options to test it out even if its slider value is at 0% probability
  * also, touching a slider causes it to reroll for all words, overwriting/forgetting your particular choice for that word

## Random whiteboardstorming

* UI and transformer stuff ![image](https://user-images.githubusercontent.com/32081933/133937172-7fca4a2f-55fb-4dd8-b1e7-2b8e6615eace.png)  
  There's another newer note to the left giving `abc.funcs = {delete(letter), stress(vowel), stressWord(word), nasalize(word), emphaticize(letter)}` and noting that `nasalize` should maybe get the whole word so it can match it to an alternative spelling if necessary (e.g. `lOsyON"` should prob match `lotion` in 3arabizi, not `losyon`)
